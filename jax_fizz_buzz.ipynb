{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FizzBuzz is the following problem:\n",
    "\n",
    "For each of the numbers 1 to 100:\n",
    "* if the number is divisible by 3, print \"fizz\"\n",
    "* if the number is divisible by 5, print \"buzz\"\n",
    "* if the number is divisible by 15, print \"fizzbuzz\"\n",
    "* otherwise, just print the number\n",
    "\"\"\"\n",
    "import json\n",
    "from typing import List\n",
    "\n",
    "import jax.numpy as np\n",
    "import wandb\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from colin_net.metrics import accuracy\n",
    "from colin_net.train import Experiment, wandb_log, wandb_notes\n",
    "\n",
    "\n",
    "def fizz_buzz_encode(x: int) -> List[int]:\n",
    "    if x % 15 == 0:\n",
    "        return [0, 0, 0, 1]\n",
    "    elif x % 5 == 0:\n",
    "        return [0, 0, 1, 0]\n",
    "    elif x % 3 == 0:\n",
    "        return [0, 1, 0, 0]\n",
    "    else:\n",
    "        return [1, 0, 0, 0]\n",
    "\n",
    "\n",
    "def binary_encode(x: int) -> List[int]:\n",
    "    \"\"\"\n",
    "    10 digit binary encoding of x\n",
    "    \"\"\"\n",
    "    return [x >> i & 1 for i in range(10)]\n",
    "\n",
    "\n",
    "train_X = np.array([binary_encode(x) for x in range(101, 1024)])\n",
    "train_Y = np.array([fizz_buzz_encode(x) for x in range(101, 1024)])\n",
    "\n",
    "test_X = np.array([binary_encode(x) for x in range(1, 101)])\n",
    "test_y = np.array([fizz_buzz_encode(x) for x in range(1, 101)])\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"experiment_name\": \"fizzbuzz\",\n",
    "    \"random_seed\": 42,\n",
    "    \"loss\": \"mean_squared_error\",\n",
    "    \"regularization\": None,\n",
    "    \"optimizer\": \"sgd\",\n",
    "    \"model_config\": {\n",
    "        \"input_dim\": 10,\n",
    "        \"output_dim\": 4,\n",
    "        \"hidden_dim\": 50,\n",
    "        \"num_hidden\": 2,\n",
    "        \"activation\": \"tanh\",\n",
    "        \"dropout_keep\": None\n",
    "    },\n",
    "    \"learing_rate\": 0.01,\n",
    "    \"batch_size\": 32,\n",
    "    \"global_step\": 50000,\n",
    "    \"log_every\": 100\n",
    "}\n",
    "\n",
    "wandb.init(project=\"colin_net_fizzbuzz\", config=config, save_code=True)\n",
    "config = wandb.config\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment.from_flattened(config)\n",
    "\n",
    "print(json.dumps(experiment.dict(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_generator = experiment.train(\n",
    "    train_X=train_X,\n",
    "    train_Y=train_Y,\n",
    "    test_X=test_X,\n",
    "    test_Y=test_y,\n",
    "    iterator_type=\"batch_iterator\",\n",
    ")\n",
    "\n",
    "bar = tqdm(total=experiment.global_step)\n",
    "for update_state in update_generator:\n",
    "    if update_state.step == 1:\n",
    "        markdown = f\"{update_state.model.json()}\"\n",
    "        wandb_notes(markdown)\n",
    "    if update_state.step % experiment.log_every == 0:\n",
    "        model = update_state.model.to_eval()\n",
    "        predicted = model.predict_proba(train_X)\n",
    "        acc_metric = float(accuracy(train_Y, predicted)) * 100\n",
    "        wandb_log({\"train_accuracy\": acc_metric}, step=update_state.step)\n",
    "        bar.set_description(f\"acc:{acc_metric:.1f}%, loss:{update_state.loss:.5f}\")\n",
    "\n",
    "        model = model.to_train()\n",
    "    bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = update_state.model\n",
    "\n",
    "# Display Predictions\n",
    "final_model = final_model.to_eval()\n",
    "probabilties = final_model.predict_proba(test_X)\n",
    "\n",
    "\n",
    "for x, (gold, prob) in enumerate(zip(test_y, probabilties)):\n",
    "    actual_idx = np.argmax(gold)\n",
    "    predicted_idx = np.argmax(prob)\n",
    "\n",
    "    labels = [str(x), \"fizz\", \"buzz\", \"fizzbuzz\"]\n",
    "    print(x, labels[predicted_idx], labels[actual_idx])\n",
    "\n",
    "\n",
    "accuracy_score = float(accuracy(test_y, probabilties))\n",
    "print(\"Accuracy: \", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
